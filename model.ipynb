{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous les datasets ont été combinés avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Chemin de base vers le dossier 'Data'\n",
    "base_dir = 'Data'\n",
    "\n",
    "# Liste pour stocker les dataframes individuels\n",
    "liste_df = []\n",
    "\n",
    "# Parcours des dossiers numérotés de '0' à '6'\n",
    "for i in range(7):\n",
    "    dossier = str(i)\n",
    "    chemin_dossier = os.path.join(base_dir, dossier)\n",
    "    fichier_csv = os.path.join(chemin_dossier, f'df_front_{i}.csv')\n",
    "    \n",
    "    try:\n",
    "        # Lecture du fichier CSV\n",
    "        df_base = pd.read_csv(fichier_csv)\n",
    "        \n",
    "        # Mise à jour du chemin des images pour qu'il pointe vers le bon dossier\n",
    "        df_base['Image_Path'] = df_base['Image_Path'].apply(lambda x: os.path.join(chemin_dossier, 'images_without_background', x))\n",
    "        \n",
    "        # Ajout du dataframe à la liste\n",
    "        liste_df.append(df_base)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Le fichier {fichier_csv} est introuvable. Passage au fichier suivant.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue avec le fichier {fichier_csv}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Concaténation de tous les dataframes en un seul\n",
    "if liste_df:\n",
    "    df = pd.concat(liste_df, ignore_index=True)\n",
    "    print(\"Tous les datasets ont été combinés avec succès.\")\n",
    "else:\n",
    "    print(\"Aucun dataset n'a été chargé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tepe/Desktop/Code/Project/Start-up/Product_Analysis/deep_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du DataFrame :\n",
      "                                          Image_Path  Condition\n",
      "0  Data/0/images_without_background/produit_1_ima...          2\n",
      "1  Data/0/images_without_background/produit_1_ima...          2\n",
      "2  Data/0/images_without_background/produit_2_ima...          3\n",
      "3  Data/0/images_without_background/produit_2_ima...          3\n",
      "4  Data/0/images_without_background/produit_2_ima...          3\n",
      "\n",
      "Distribution des classes dans le dataset complet :\n",
      "Condition\n",
      "3    6746\n",
      "2    2925\n",
      "4    2921\n",
      "1     644\n",
      "0     459\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Colonnes du DataFrame\n",
    "IMAGE_COLUMN = 'Image_Path'\n",
    "LABEL_COLUMN = 'Condition'\n",
    "\n",
    "# Paramètres du modèle\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (380, 380)  # Taille d'entrée pour EfficientNetB4\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "NUM_CLASSES = 5  # Conditions de 0 à 4\n",
    "\n",
    "\n",
    "# Affichage des premières lignes pour vérification\n",
    "print(\"Aperçu du DataFrame :\")\n",
    "print(df.head())\n",
    "\n",
    "# Analyse de la distribution des classes\n",
    "print(\"\\nDistribution des classes dans le dataset complet :\")\n",
    "print(df['Condition'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre d'échantillons dans l'ensemble d'entraînement : 10956\n",
      "Nombre d'échantillons dans l'ensemble de validation : 1369\n",
      "Nombre d'échantillons dans l'ensemble de test : 1370\n"
     ]
    }
   ],
   "source": [
    "# Séparation initiale en entraînement (80%) et temporaire (20%)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['Condition'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Séparation de l'ensemble temporaire en validation (10%) et test (10%)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['Condition'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nNombre d'échantillons dans l'ensemble d'entraînement : {len(train_df)}\")\n",
    "print(f\"Nombre d'échantillons dans l'ensemble de validation : {len(val_df)}\")\n",
    "print(f\"Nombre d'échantillons dans l'ensemble de test : {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path, label):\n",
    "    # Lecture de l'image depuis le fichier\n",
    "    image = tf.io.read_file(path)\n",
    "    \n",
    "    # Décodage de l'image en format RGB\n",
    "    image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
    "    \n",
    "    # Conversion des pixels en flottants entre 0 et 1\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    # Redimensionnement avec padding pour maintenir le ratio d'aspect\n",
    "    image = tf.image.resize_with_pad(image, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "    \n",
    "    # Application de la normalisation spécifique à EfficientNetB4\n",
    "    image = tf.keras.applications.efficientnet.preprocess_input(image * 255.0)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des transformations d'augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "    # Vous pouvez ajouter d'autres couches d'augmentation si nécessaire\n",
    "])\n",
    "\n",
    "def augment(image, label):\n",
    "    image = data_augmentation(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, shuffle=True, augment_data=False):\n",
    "    # Extraction des chemins d'images et des labels\n",
    "    paths = df[IMAGE_COLUMN].values\n",
    "    labels = df[LABEL_COLUMN].values\n",
    "    \n",
    "    # Création d'un dataset TensorFlow à partir des chemins et labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    \n",
    "    # Application de la fonction de prétraitement\n",
    "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # Mélange des données si nécessaire\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(df))\n",
    "    \n",
    "    # Application de l'augmentation des données si spécifié\n",
    "    if augment_data:\n",
    "        dataset = dataset.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # Batching et préfetching pour optimiser les performances\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des ensembles d'entraînement, de validation et de test\n",
    "train_dataset = create_dataset(train_df, shuffle=True, augment_data=True)\n",
    "val_dataset = create_dataset(val_df, shuffle=False, augment_data=False)\n",
    "test_dataset = create_dataset(test_df, shuffle=False, augment_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids de classe :  {0: np.float64(5.9705722070844685), 1: np.float64(4.254757281553398), 2: np.float64(0.9364102564102564), 3: np.float64(0.40600333518621456), 4: np.float64(0.937612323491656)}\n"
     ]
    }
   ],
   "source": [
    "# Extraction des labels de l'ensemble d'entraînement\n",
    "train_labels = train_df[LABEL_COLUMN].values\n",
    "\n",
    "# Calcul des poids de classe\n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "\n",
    "# Création d'un dictionnaire des poids de classe\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "print(\"Poids de classe : \", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de couches dans le modèle de base :  475\n"
     ]
    }
   ],
   "source": [
    "# Définition de la taille d'entrée\n",
    "IMAGE_SIZE = (380, 380, 3)  # EfficientNetB4 nécessite des images de taille 380x380 avec 3 canaux de couleur\n",
    "\n",
    "\n",
    "# Chargement du modèle EfficientNetB4 sans les couches supérieures (top layers)\n",
    "base_model = EfficientNetB4(\n",
    "    include_top=False,  # Nous allons ajouter nos propres couches supérieures\n",
    "    weights='imagenet',  # Utiliser les poids pré-entraînés sur ImageNet\n",
    "    input_shape=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "# Congélation des couches du modèle de base pour le transfert learning initial\n",
    "base_model.trainable = False\n",
    "\n",
    "# Vérification des couches congelées\n",
    "print(\"Nombre de couches dans le modèle de base : \", len(base_model.layers))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle final en ajoutant des couches supérieures personnalisées\n",
    "model = models.Sequential([\n",
    "    base_model,  # Le modèle de base EfficientNetB4\n",
    "    layers.GlobalAveragePooling2D(),  # Réduction de la dimensionnalité\n",
    "    layers.Dropout(0.5),  # Dropout pour éviter le surapprentissage\n",
    "    layers.Dense(256, activation='relu'),  # Couche dense avec activation ReLU\n",
    "    layers.Dropout(0.5),  # Autre couche de Dropout\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')  # Couche de sortie avec activation softmax\n",
    "])\n",
    "\n",
    "# Affichage de la structure du modèle\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),  # Optimiseur Adam avec un taux d'apprentissage initial\n",
    "    loss='sparse_categorical_crossentropy',  # Fonction de perte adaptée aux labels entiers\n",
    "    metrics=['accuracy']  # Métrique d'évaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des callbacks\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "    'best_model.keras',  # Chemin où enregistrer le meilleur modèle\n",
    "    save_best_only=True,  # Enregistrer uniquement le modèle avec la meilleure performance sur la validation\n",
    "    monitor='val_accuracy',  # Surveiller la précision sur l'ensemble de validation\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "earlystop_cb = callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',  # Surveiller la précision sur l'ensemble de validation\n",
    "    patience=10,  # Arrêter l'entraînement après 10 époques sans amélioration\n",
    "    restore_best_weights=True  # Restaurer les poids du meilleur modèle\n",
    ")\n",
    "\n",
    "reduce_lr_cb = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',  # Surveiller la précision sur l'ensemble de validation\n",
    "    factor=0.2,  # Facteur de réduction du taux d'apprentissage\n",
    "    patience=5,  # Patience avant de réduire le taux d'apprentissage\n",
    "    min_lr=1e-6  # Taux d'apprentissage minimum\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m783s\u001b[0m 2s/step - accuracy: 0.2285 - loss: 1.6585 - val_accuracy: 0.2725 - val_loss: 1.5591 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m775s\u001b[0m 2s/step - accuracy: 0.2371 - loss: 1.5898 - val_accuracy: 0.2498 - val_loss: 1.5460 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m763s\u001b[0m 2s/step - accuracy: 0.2486 - loss: 1.4993 - val_accuracy: 0.2009 - val_loss: 1.5616 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 2s/step - accuracy: 0.2422 - loss: 1.5019 - val_accuracy: 0.2484 - val_loss: 1.4958 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 2s/step - accuracy: 0.2652 - loss: 1.5050 - val_accuracy: 0.2162 - val_loss: 1.5545 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 2s/step - accuracy: 0.2556 - loss: 1.4785 - val_accuracy: 0.2243 - val_loss: 1.5018 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 2s/step - accuracy: 0.2622 - loss: 1.4129 - val_accuracy: 0.2717 - val_loss: 1.5312 - learning_rate: 2.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 2s/step - accuracy: 0.2698 - loss: 1.4114 - val_accuracy: 0.2608 - val_loss: 1.5189 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 2s/step - accuracy: 0.2863 - loss: 1.4178 - val_accuracy: 0.2498 - val_loss: 1.5140 - learning_rate: 2.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 2s/step - accuracy: 0.2744 - loss: 1.4179 - val_accuracy: 0.2630 - val_loss: 1.5150 - learning_rate: 2.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m745s\u001b[0m 2s/step - accuracy: 0.2793 - loss: 1.4167 - val_accuracy: 0.2535 - val_loss: 1.5160 - learning_rate: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Nombre d'époques initial\n",
    "initial_epochs = 30\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(\n",
    "    train_dataset,  # Ensemble d'entraînement\n",
    "    epochs=initial_epochs,  # Nombre d'époques\n",
    "    validation_data=val_dataset,  # Ensemble de validation\n",
    "    class_weight=class_weights,  # Poids de classe pour gérer le déséquilibre\n",
    "    callbacks=[checkpoint_cb, earlystop_cb, reduce_lr_cb]  # Callbacks définis précédemment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m900s\u001b[0m 3s/step - accuracy: 0.2685 - loss: 1.6587 - val_accuracy: 0.2191 - val_loss: 1.5966 - learning_rate: 1.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m892s\u001b[0m 3s/step - accuracy: 0.2388 - loss: 1.6092 - val_accuracy: 0.2089 - val_loss: 1.6068 - learning_rate: 1.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 3s/step - accuracy: 0.2533 - loss: 1.5069 - val_accuracy: 0.1980 - val_loss: 1.5930 - learning_rate: 1.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 3s/step - accuracy: 0.2527 - loss: 1.5379 - val_accuracy: 0.2067 - val_loss: 1.5738 - learning_rate: 1.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m884s\u001b[0m 3s/step - accuracy: 0.2571 - loss: 1.5312 - val_accuracy: 0.2096 - val_loss: 1.5638 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 3s/step - accuracy: 0.2641 - loss: 1.4999 - val_accuracy: 0.2118 - val_loss: 1.5506 - learning_rate: 1.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 3s/step - accuracy: 0.2688 - loss: 1.4837 - val_accuracy: 0.2038 - val_loss: 1.5533 - learning_rate: 2.0000e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m889s\u001b[0m 3s/step - accuracy: 0.2700 - loss: 1.4794 - val_accuracy: 0.2075 - val_loss: 1.5519 - learning_rate: 2.0000e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m889s\u001b[0m 3s/step - accuracy: 0.2689 - loss: 1.4457 - val_accuracy: 0.2067 - val_loss: 1.5496 - learning_rate: 2.0000e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m886s\u001b[0m 3s/step - accuracy: 0.2724 - loss: 1.4724 - val_accuracy: 0.2082 - val_loss: 1.5460 - learning_rate: 2.0000e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m882s\u001b[0m 3s/step - accuracy: 0.2633 - loss: 1.4727 - val_accuracy: 0.2096 - val_loss: 1.5476 - learning_rate: 2.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Définir combien de couches du modèle de base seront dégelées\n",
    "total_layers = len(base_model.layers)\n",
    "fine_tune_at = total_layers - 30  # Dégeler les dernières 30 couches\n",
    "\n",
    "# Congélation partielle du modèle de base\n",
    "base_model.trainable = True\n",
    "\n",
    "# Congélation des couches jusqu'à fine_tune_at\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompilation du modèle avec un taux d'apprentissage plus bas pour le fine-tuning\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5),  # Taux d'apprentissage réduit\n",
    "    loss='sparse_categorical_crossentropy',  # Même fonction de perte\n",
    "    metrics=['accuracy']  # Même métrique\n",
    ")\n",
    "\n",
    "# Nombre d'époques pour le fine-tuning\n",
    "fine_tune_epochs = 20\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "# Entraînement avec fine-tuning\n",
    "history_fine = model.fit(\n",
    "    train_dataset,  # Ensemble d'entraînement\n",
    "    epochs=total_epochs,  # Nombre total d'époques\n",
    "    initial_epoch=history.epoch[-1],  # Commencer après les époques initiales\n",
    "    validation_data=val_dataset,  # Ensemble de validation\n",
    "    class_weight=class_weights,  # Poids de classe\n",
    "    callbacks=[checkpoint_cb, earlystop_cb, reduce_lr_cb]  # Callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
